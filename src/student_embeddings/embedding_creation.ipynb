{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from train_lstm import instantiate_model, LSTM_AE, QNA_DATA_DIR, BASE_DATA_DIR\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCQDataset(torch.utils.data.Dataset):\n",
    "    _nlp_model = None\n",
    "\n",
    "    @property\n",
    "    def nlp_model(self):\n",
    "        if MCQDataset._nlp_model:\n",
    "            return MCQDataset._nlp_model\n",
    "        \n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        MCQDataset._nlp_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "        return MCQDataset._nlp_model\n",
    "\n",
    "\n",
    "    def __init__(self, datapath, seq_len=5, progress_bar=True):\n",
    "        self.datapath = datapath\n",
    "        self.seq_len = seq_len\n",
    "        self.progress_bar = progress_bar\n",
    "\n",
    "        import os\n",
    "        self.df = pd.read_pickle(self.datapath)\n",
    "            \n",
    "        # preprocess topic data\n",
    "        self.df['question_embedding'] = self._create_q_embeddings()\n",
    "        self.df['answer_embedding']= self._create_a_embeddings()\n",
    "\n",
    "    def _create_q_embeddings(self):\n",
    "        # create embeddings for each topic\n",
    "        embeddings = self.nlp_model.to(device).encode(self.df[\"question\"], show_progress_bar=self.progress_bar, batch_size=2048)\n",
    "        return list(map(lambda x: np.squeeze(x), np.split(embeddings, embeddings.shape[0])))\n",
    "    def _create_a_embeddings(self):\n",
    "        # create embeddings for each topic\n",
    "        embeddings = self.nlp_model.to(device).encode(self.df[\"choice\"], show_progress_bar=self.progress_bar, batch_size=2048)\n",
    "        return list(map(lambda x: np.squeeze(x), np.split(embeddings, embeddings.shape[0])))\n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < 0:\n",
    "            idx = len(self.df) + idx\n",
    "\n",
    "        df2 = self.df[self.df[\"user_id\"] == self.df.iloc[idx][\"user_id\"]].reset_index()\n",
    "        df2 = df2.sort_values(by=\"start_time\").reset_index(drop=True)\n",
    "        indx = df2[df2[\"index\"] == idx].index[0]\n",
    "\n",
    "        \n",
    "        if indx >= self.seq_len:\n",
    "            seq_before = df2.iloc[indx-self.seq_len+1 : indx+1]\n",
    "        else:\n",
    "            seq_before = df2.iloc[0: indx+1]\n",
    "\n",
    "\n",
    "        data = torch.stack(\n",
    "            seq_before.apply(lambda x: np.concatenate((x['question_embedding'], x['answer_embedding'])), axis=1)\n",
    "              .apply(lambda x: torch.tensor(x, dtype=torch.float32))\n",
    "              .tolist()\n",
    "        )\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ecc18698a664937be863bb589cf8fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "893b3473b01a4b2a909c6146b7231240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = MCQDataset(f\"{QNA_DATA_DIR}/all_data_qna_expanded.pkl\")\n",
    "# dataset = MCQDataset(f\"{QNA_DATA_DIR}/validation/qna_expanded.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 20\n",
    "h_dims = [384]\n",
    "lstm_checkpoint_path = f\"{BASE_DATA_DIR}/../checkpoints/seq_len_{seq_len}_h_dims_{len(h_dims)}/model_100.pt\"\n",
    "\n",
    "model = instantiate_model(LSTM_AE, dataset, 384, h_dims=h_dims)\n",
    "model.load_state_dict(torch.load(lstm_checkpoint_path))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c43d729e62f4fe8a96a58416f0a9fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/220977 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from train_lstm import get_encodings\n",
    "from pathlib import Path\n",
    "\n",
    "dataset.seq_len = seq_len\n",
    "embeddings = get_encodings(model, dataset)\n",
    "\n",
    "# embeddings to tensor\n",
    "embeddings = torch.stack(embeddings)\n",
    "embeddings = embeddings.detach().cpu()\n",
    "\n",
    "Path(f\"{BASE_DATA_DIR}/lernnavi/embeddings\").mkdir(parents=True, exist_ok=True)\n",
    "torch.save(embeddings, f\"{BASE_DATA_DIR}/lernnavi/embeddings/lstm_seq_len_{seq_len}_h_dims_{len(h_dims)}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"lucazed/LernnaviBERT\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"lucazed/LernnaviBERT\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def remove_html_tags(input):\n",
    "    soup = BeautifulSoup(input, 'html.parser')\n",
    "    return soup.get_text().strip()\n",
    "\n",
    "class MCQDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, datapath, seq_len=5, progress_bar=True):\n",
    "        self.datapath = datapath\n",
    "        self.seq_len = seq_len\n",
    "        self.progress_bar = progress_bar\n",
    "\n",
    "        self.df = pd.read_pickle(self.datapath)\n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < 0:\n",
    "            idx = len(self.df) + idx\n",
    "\n",
    "        df2 = self.df[self.df[\"user_id\"] == self.df.iloc[idx][\"user_id\"]].reset_index()\n",
    "        df2 = df2.sort_values(by=\"start_time\").reset_index(drop=True)\n",
    "        indx = df2[df2[\"index\"] == idx].index[0]\n",
    "\n",
    "        \n",
    "        if indx >= self.seq_len:\n",
    "            seq_before = df2.iloc[indx-self.seq_len+1 : indx+1]\n",
    "        else:\n",
    "            seq_before = df2.iloc[0: indx+1]\n",
    "\n",
    "\n",
    "        # return a string with \"Q: question\\nA: answer\\n\" for each question-answer pair\n",
    "        data = f\"{tokenizer.sep_token}\".join(seq_before.apply(lambda x: f\"Q: {x['question']}{tokenizer.sep_token}A: {x['choice']}\", axis=1).values)\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "\n",
    "            return remove_html_tags(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 10\n",
    "dataset = MCQDataset(f\"{QNA_DATA_DIR}/all_data_qna_expanded.pkl\", seq_len=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 220977/220977 [3:11:35<00:00, 19.22it/s]  \n"
     ]
    }
   ],
   "source": [
    "bert_embeddings = []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        bert_embeddings.append(model(**tokenizer(dataset[i], return_tensors=\"pt\", truncation=True).to(device), output_hidden_states=True).hidden_states[-1].squeeze(0).mean(0).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_embeddings = torch.stack(bert_embeddings)\n",
    "torch.save(bert_embeddings, f\"{BASE_DATA_DIR}/lernnavi/embeddings/bert_seq_len_{seq_len}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mistral 7B embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f98da3f5124970a05d81b3f495f54a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 222/220977 [00:32<9:01:37,  6.79it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataset))):\n\u001b[0;32m----> 4\u001b[0m         mistral_embeddings\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4096\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mistral_embeddings = []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(dataset))):\n",
    "        mistral_embeddings.append(model(**tokenizer(dataset[i], return_tensors=\"pt\", truncation=True, max_length=4096).to(device), output_hidden_states=True).hidden_states[-1].squeeze(0).mean(0).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_embeddings = torch.stack(mistral_embeddings)\n",
    "torch.save(mistral_embeddings, f\"{BASE_DATA_DIR}/lernnavi/embeddings/mistral_seq_len_{seq_len}.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlbd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
