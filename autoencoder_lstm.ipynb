{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sequitur\n",
      "  Downloading sequitur-1.2.4.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gdown\n",
      "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
      "Collecting sentence_transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from sequitur) (2.0.1+cu117)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.9.0)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.28.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from gdown) (1.16.0)\n",
      "Collecting tqdm (from gdown)\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.2)\n",
      "Collecting transformers<5.0.0,>=4.6.0 (from sentence_transformers)\n",
      "  Downloading transformers-4.30.0-py3-none-any.whl (7.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.15.2+cu117)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.24.1)\n",
      "Collecting scikit-learn (from sentence_transformers)\n",
      "  Downloading scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scipy (from sentence_transformers)\n",
      "  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nltk (from sentence_transformers)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece (from sentence_transformers)\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.4.0 (from sentence_transformers)\n",
      "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec (from huggingface-hub>=0.4.0->sentence_transformers)\n",
      "  Downloading fsspec-2023.5.0-py3-none-any.whl (160 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.4.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->sequitur) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->sequitur) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->sequitur) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->sequitur) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->sequitur) (3.25.0)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->sequitur) (15.0.7)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.6.0->sentence_transformers)\n",
      "  Downloading regex-2023.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (770 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.4/770.4 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<5.0.0,>=4.6.0->sentence_transformers)\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers<5.0.0,>=4.6.0->sentence_transformers)\n",
      "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
      "Collecting click (from nltk->sentence_transformers)\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib (from nltk->sentence_transformers)\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->sentence_transformers)\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (9.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->sequitur) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->sequitur) (1.2.1)\n",
      "Building wheels for collected packages: sequitur, sentence_transformers\n",
      "  Building wheel for sequitur (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sequitur: filename=sequitur-1.2.4-py3-none-any.whl size=9607 sha256=5f99aaa4554b6a1319fb343fbb17b37b1712f84434f62577097f635bbcb05839\n",
      "  Stored in directory: /root/.cache/pip/wheels/98/af/0d/45fde9d0819faa8a6d53b85f36576aaf2446b6a57eae68fc27\n",
      "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=3db607300645e0a26bc94bfdf693554de6c23fe7fae6260b7a07279041ea7768\n",
      "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
      "Successfully built sequitur sentence_transformers\n",
      "Installing collected packages: tokenizers, sentencepiece, safetensors, tqdm, threadpoolctl, scipy, regex, PySocks, joblib, fsspec, click, scikit-learn, nltk, huggingface-hub, transformers, gdown, sequitur, sentence_transformers\n",
      "Successfully installed PySocks-1.7.1 click-8.1.3 fsspec-2023.5.0 gdown-4.7.1 huggingface-hub-0.15.1 joblib-1.2.0 nltk-3.8.1 regex-2023.6.3 safetensors-0.3.1 scikit-learn-1.2.2 scipy-1.10.1 sentence_transformers-2.2.2 sentencepiece-0.1.99 sequitur-1.2.4 threadpoolctl-3.1.0 tokenizers-0.13.3 tqdm-4.65.0 transformers-4.30.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install sequitur gdown sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1l3IhqCEErRu_gls34kOdt4V6kmmeQzXE\n",
      "To: /workspace/train_qna.csv\n",
      "100%|██████████| 33.9M/33.9M [00:00<00:00, 37.1MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1_MmyHp7u384ZSfF1Ww0A1TCrj9Yg5ZQD\n",
      "To: /workspace/val_qna.csv\n",
      "100%|██████████| 10.2M/10.2M [00:00<00:00, 22.4MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1hpb5AXrgxu8GQpAkGnYNl_SnnPEWAFJ9\n",
      "To: /workspace/test_qna.csv\n",
      "100%|██████████| 8.20M/8.20M [00:00<00:00, 23.1MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./test_qna.csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "import os\n",
    "\n",
    "\n",
    "# same as the above, and you can copy-and-paste a URL from Google Drive with fuzzy=True\n",
    "output = \"./train_qna.csv\"\n",
    "url = \"https://drive.google.com/file/d/1l3IhqCEErRu_gls34kOdt4V6kmmeQzXE/view?usp=sharing\"\n",
    "gdown.download(url=url, output=output, quiet=False, fuzzy=True)\n",
    "\n",
    "\n",
    "output = \"./val_qna.csv\"\n",
    "url = \"https://drive.google.com/file/d/1_MmyHp7u384ZSfF1Ww0A1TCrj9Yg5ZQD/view?usp=sharing\"\n",
    "gdown.download(url=url, output=output, quiet=False, fuzzy=True)\n",
    "\n",
    "output = \"./test_qna.csv\"\n",
    "url = \"https://drive.google.com/file/d/1hpb5AXrgxu8GQpAkGnYNl_SnnPEWAFJ9/view?usp=sharing\"\n",
    "gdown.download(url=url, output=output, quiet=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class MCQDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    _nlp_model = None\n",
    "\n",
    "    @property\n",
    "    def nlp_model(self):\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        if MCQDataset._nlp_model:\n",
    "            return MCQDataset._nlp_model\n",
    "        \n",
    "        MCQDataset._nlp_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "        return MCQDataset._nlp_model\n",
    "\n",
    "\n",
    "    def __init__(self, datapath, seq_len=5):\n",
    "        self.datapath = datapath\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        import os\n",
    "        self.df = pd.read_csv(self.datapath)\n",
    "            \n",
    "        # preprocess topic data\n",
    "        self.df['question_embedding'] = self._create_q_embeddings()\n",
    "        self.df['answer_embedding']= self._create_a_embeddings()\n",
    "\n",
    "    def _create_q_embeddings(self):\n",
    "        # create embeddings for each topic\n",
    "        embeddings = self.nlp_model.to(device).encode(self.df[\"question\"])\n",
    "        return list(map(lambda x: np.squeeze(x), np.split(embeddings, embeddings.shape[0])))\n",
    "    def _create_a_embeddings(self):\n",
    "        # create embeddings for each topic\n",
    "        embeddings = self.nlp_model.to(device).encode(self.df[\"choice\"])\n",
    "        return list(map(lambda x: np.squeeze(x), np.split(embeddings, embeddings.shape[0])))\n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "#         display(self.df)\n",
    "        df2 = self.df[self.df[\"user_id\"] == self.df.iloc[idx][\"user_id\"]].reset_index(drop=True)\n",
    "        df2 = df2.sort_values(by=\"start_time\").reset_index(drop=True)\n",
    "        indx = df2[(df2[\"question\"]==self.df.iloc[idx][\"question\"]) & (df2[\"choice\"]==self.df.iloc[idx][\"choice\"])].index[0]\n",
    "\n",
    "        \n",
    "        if indx >= self.seq_len:\n",
    "            seq_before = df2.iloc[indx-self.seq_len+1 : indx+1]\n",
    "        else:\n",
    "            seq_before = df2.iloc[0: indx+1]\n",
    "\n",
    "\n",
    "        data = torch.stack(\n",
    "            seq_before.apply(lambda x: np.concatenate((x['question_embedding'], x['answer_embedding'])), axis=1)\n",
    "              .apply(lambda x: torch.tensor(x, dtype=torch.float32))\n",
    "              .tolist()\n",
    "        )\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6764a2f12c4fc2b2005276f76965b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)0fe39/.gitattributes:   0%|          | 0.00/968 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735258e5d0a442b08d7f317407bbe3b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b391536a4d41d09eb097ef7c92852d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)83e900fe39/README.md:   0%|          | 0.00/3.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b8f552873f5447fa02d4d06e4d5032e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)e900fe39/config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c189297ea34cfdb1a6777aaf15b139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "932d605ac93f44f5bfc2e7727aa81ca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a80b8454864930a9cdc9475bdb84dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a2930235ded49aab11d50f2d665ae81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99f6798ce58447d790b8eaebb029aa8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0571d0e764174501bed109f92ebfb531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60dc46ea9a0040f8b188681791f7dfd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "561d1d1d18d844188301b91d43e6da78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading unigram.json:   0%|          | 0.00/14.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01326d647aa6429ebf4d5aad106bd2be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)900fe39/modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = MCQDataset('./train_qna.csv', seq_len=10)\n",
    "val_dataset = MCQDataset('./val_qna.csv', seq_len=10)\n",
    "test_dataset = MCQDataset('./test_qna.csv', seq_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30d6c0b1ca914dea9a76ba7b394cd042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/145620 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aecdc1b5b3b480ea3f9ef992812ac65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43006 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434bf99cd780440fa1bdb09391a1a65b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_index_to_filter = []\n",
    "train_filtered = []\n",
    "for x in tqdm(train_dataset):\n",
    "    train_index_to_filter.append(x.shape[0] > 1)\n",
    "    if x.shape[0] > 1:\n",
    "        train_filtered.append(x)\n",
    "\n",
    "\n",
    "val_index_to_filter = []\n",
    "val_filtered = []\n",
    "for x in tqdm(val_dataset):\n",
    "    val_index_to_filter.append(x.shape[0] > 1)\n",
    "    if x.shape[0] > 1:\n",
    "        val_filtered.append(x)\n",
    "\n",
    "\n",
    "test_index_to_filter = []\n",
    "test_filtered = []\n",
    "for x in tqdm(test_dataset):\n",
    "    test_index_to_filter.append(x.shape[0] > 1)\n",
    "    if x.shape[0] > 1:\n",
    "        test_filtered.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "def get_device():\n",
    "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def instantiate_model(model, train_set, encoding_dim, **kwargs):\n",
    "    if model.__name__ in (\"LINEAR_AE\", \"LSTM_AE\"):\n",
    "        return model(train_set[-1].shape[-1], encoding_dim, **kwargs)\n",
    "    elif model.__name__ == \"CONV_LSTM_AE\":\n",
    "        if len(train_set[-1].shape) == 3:  # 2D elements\n",
    "            return model(train_set[-1].shape[-2:], encoding_dim, **kwargs)\n",
    "        elif len(train_set[-1].shape) == 4:  # 3D elements\n",
    "            return model(train_set[-1].shape[-3:], encoding_dim, **kwargs)\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_model(model, val_set, epoch, criterion, device):\n",
    "    model.eval()\n",
    "    \n",
    "    losses = []\n",
    "    for x in tqdm(val_set, desc=f\"Val Epoch {epoch: 3d}\"):\n",
    "        x = x.to(device)\n",
    "        x_prime = model(x)\n",
    "        \n",
    "        loss = criterion(x_prime, x)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "    return mean(losses)\n",
    "        \n",
    "\n",
    "def train_model(\n",
    "    model, train_set, val_set, verbose, lr, epochs, denoise, clip_value, device=None, save_path=Path(\"./checkpoints\")\n",
    "):\n",
    "    if device is None:\n",
    "        device = get_device()\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = MSELoss(reduction=\"sum\")\n",
    "\n",
    "    mean_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "\n",
    "        # # Reduces learning rate every 50 epochs\n",
    "        # if not epoch % 50:\n",
    "        #     for param_group in optimizer.param_groups:\n",
    "        #         param_group[\"lr\"] = lr * (0.993 ** epoch)\n",
    "\n",
    "        losses = []\n",
    "        for x in tqdm(train_set, desc=f\"Train Epoch {epoch: 3d}\"):\n",
    "            x = x.to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            x_prime = model(x)\n",
    "\n",
    "            loss = criterion(x_prime, x)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "           \n",
    "\n",
    "            # Gradient clipping on norm\n",
    "            if clip_value is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        mean_loss = mean(losses)\n",
    "        mean_losses.append(mean_loss)\n",
    "        \n",
    "        torch.save(model.state_dict(), str(save_path / f\"model_{epoch:03d}.pt\"))\n",
    "\n",
    "        val_loss = validate_model(model, val_set, epoch, criterion, device)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Epoch: {epoch}, Train loss: {mean_loss}, Validation Loss: {val_loss}\")\n",
    "\n",
    "    return mean_losses, val_losses\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_encodings(model, train_set, device=None):\n",
    "    if device is None:\n",
    "        device = get_device()\n",
    "    model.eval()\n",
    "    encodings = [model.encoder(x.to(device)) for x in tqdm(train_set)]\n",
    "    return encodings\n",
    "\n",
    "\n",
    "######\n",
    "# MAIN\n",
    "######\n",
    "\n",
    "\n",
    "def quick_train(\n",
    "    model,\n",
    "    train_set,\n",
    "    val_set,\n",
    "    encoding_dim,\n",
    "    verbose=False,\n",
    "    lr=1e-3,\n",
    "    epochs=50,\n",
    "    clip_value=1,\n",
    "    denoise=False,\n",
    "    device=None,\n",
    "    save_path=Path(\"./checkpoints\"),\n",
    "    **kwargs,\n",
    "):\n",
    "    model = instantiate_model(model, train_set, encoding_dim, **kwargs)\n",
    "\n",
    "    save_path.mkdir(parents=True, exist_ok=True)\n",
    "    train_losses, val_losses = train_model(\n",
    "        model, train_set, val_set, verbose, lr, epochs, denoise, clip_value, device, save_path\n",
    "    )\n",
    "\n",
    "    return model.encoder, model.decoder, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb27508eb4a46f9a6136c0470ae1182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch   1:   0%|          | 0/135267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a6f4e848a0248d985c3a7dfa93944b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Epoch   1:   0%|          | 0/35007 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 156.61422064648283, Validation Loss: 90.17015298436436\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fcb638c96dd47f082a5af777b0eb9e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch   2:   0%|          | 0/135267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92033a6b78e4a50a033d7997165403c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Epoch   2:   0%|          | 0/35007 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train loss: 122.75223265864777, Validation Loss: 89.74077505458817\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdbcaa5526774cbbab118c3fecf6fba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch   3:   0%|          | 0/135267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train loss: 122.94635681162087, Validation Loss: 89.98076720173303\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1a58df6c3c4d4ea0e4f3cc6504b681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch   4:   0%|          | 0/135267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train loss: 122.91766345850905, Validation Loss: 90.34999194363006\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac5d42ac3a274424a077e9a0961044f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch   6:   0%|          | 0/135267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deec0ea4b1cb4fe29c90b2cf2eb71e26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Epoch  11:   0%|          | 0/35007 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Train loss: 123.03513567070489, Validation Loss: 90.16574310107461\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7188f9331f34c84969740193bae4dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch  12:   0%|          | 0/135267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sequitur.models import LSTM_AE\n",
    "\n",
    "encoder, decoder, train_losses, val_losses = quick_train(LSTM_AE, train_gpu, val_filtered, encoding_dim=512, verbose=True, lr=1e-3, epochs=50, denoise=False, h_dims=[512, 512, 512],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-08T14:49:57.114945Z",
     "iopub.status.idle": "2023-06-08T14:49:57.115931Z",
     "shell.execute_reply": "2023-06-08T14:49:57.115698Z",
     "shell.execute_reply.started": "2023-06-08T14:49:57.115676Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from IPython.display import FileLink, display\n",
    "\n",
    "def download_file(path, download_file_name):\n",
    "    os.chdir('/kaggle/working/')\n",
    "    zip_name = f\"/kaggle/working/{download_file_name}.zip\"\n",
    "    command = f\"zip {zip_name} {path} -r\"\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        print(\"Unable to run zip command!\")\n",
    "        print(result.stderr)\n",
    "        return\n",
    "    display(FileLink(f'{download_file_name}.zip'))\n",
    "    \n",
    "download_file(\"./checkpoints\", \"out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = plt.subplot()\n",
    "sns.lineplot(x=range(1, len(train_losses)), y=train_losses[1:], label=\"Train Loss\", ax=ax)\n",
    "sns.lineplot(x=range(1, len(val_losses)), y=val_losses[1:], label=\"Validation Loss\", ax=ax)\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "932c9e1ee83a493282118bbaa7e8bf29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Epoch   1:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02002157229902223\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dbd63c3ba244ac5ad6813cfa9f1d9fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Epoch   1:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019925999245140703\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb70b12089aa4e7d9cc83a1017bccdba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Epoch   1:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019988625720608978\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be894262f0de4cfba4a9bede02e25047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Epoch   1:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019891070815501736\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3432f2b692e040e888668dcf08ed9275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Epoch   1:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.020066130213579163\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b2761fc4f1644b9aeb03839ecb235c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Epoch   1:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.020145628695655615\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e4cd48003c4220b2e94e52a35aaeb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Epoch   1:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02007863878160715\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40dfa38e159947889aca6eb109b4bffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Epoch   1:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.020226230228925123\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695ba7329ac349bbb5308743bdcdef8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Epoch   1:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02002329792706296\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f2c34ddd0354df3b49b2c78dc1ed77f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Epoch   1:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02014954390199855\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560b982ad6d2467587cd4101e69c926d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Val Epoch   1:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0200246145113837\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "for mpath in glob.glob(\"./checkpoints/*\"):\n",
    "    ckpt = torch.load(mpath)\n",
    "    mloaded = LSTM_AE(val_filtered[-1].shape[-1], 512, h_dims=[512, 512, 512])\n",
    "    mloaded.load_state_dict(ckpt)\n",
    "    print(validate_model(mloaded.to(device), val_filtered[:10000], 1, torch.nn.functional.mse_loss, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae5dfecf3384a38a3d08acaeb2d5f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/145620 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6bfa7107538453ab078355d9dfe34f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43006 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5999e91f4234c26a4fd2ee93ffd9072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ckpt = torch.load(\"./model_004.pt\")\n",
    "mloaded = LSTM_AE(val_filtered[-1].shape[-1], 512, h_dims=[512, 512, 512])\n",
    "mloaded.load_state_dict(ckpt)\n",
    "mloaded = mloaded.to(device)\n",
    "\n",
    "train_embeddings = get_encodings(mloaded, train_dataset)\n",
    "val_embeddings = get_encodings(mloaded, val_dataset)\n",
    "test_embeddings = get_encodings(mloaded, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=124QDhAo21G4jWOA9L-LIKMjZe8PY0zE0\n",
      "To: /workspace/train_qna_initial.pkl\n",
      "100%|██████████| 63.1M/63.1M [00:25<00:00, 2.52MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1cnQGQ6Y--Cd3Ri_vQuOgsRmZ-BNhznoY\n",
      "To: /workspace/val_qna_initial.pkl\n",
      "100%|██████████| 18.9M/18.9M [00:01<00:00, 16.0MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=16Kis7d7tTu9SUwBT6kZt4kfKvW1M0q6d\n",
      "To: /workspace/test_qna_initial.pkl\n",
      "100%|██████████| 14.1M/14.1M [00:01<00:00, 12.6MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./test_qna_initial.pkl'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = \"./train_qna_initial.pkl\"\n",
    "url = \"https://drive.google.com/file/d/124QDhAo21G4jWOA9L-LIKMjZe8PY0zE0/view?usp=sharing\"\n",
    "gdown.download(url=url, output=output, quiet=False, fuzzy=True)\n",
    "\n",
    "output = \"./val_qna_initial.pkl\"\n",
    "url = \"https://drive.google.com/file/d/1cnQGQ6Y--Cd3Ri_vQuOgsRmZ-BNhznoY/view?usp=sharing\"\n",
    "gdown.download(url=url, output=output, quiet=False, fuzzy=True)\n",
    "\n",
    "output = \"./test_qna_initial.pkl\"\n",
    "url = \"https://drive.google.com/file/d/16Kis7d7tTu9SUwBT6kZt4kfKvW1M0q6d/view?usp=sharing\"\n",
    "gdown.download(url=url, output=output, quiet=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(\"./train_qna.csv\", )\n",
    "train_csv['embeddings'] = list(map(lambda x: x.detach().cpu().numpy(), train_embeddings))\n",
    "\n",
    "train_qna_pkl = pd.read_pickle(\"./train_qna_initial.pkl\")[[\"user_id\", \"multiple_responses\", \"question\", \"choices\", \"correct\", \"student_answer\", \"start_time\"]]\n",
    "train_qna_pkl[\"embedding\"] = train_csv.groupby(\"question_index\").apply(lambda x: x.iloc[-1])[\"embeddings\"]\n",
    "train_qna_pkl.to_pickle(\"./train_pkl_with_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_csv = pd.read_csv(\"./val_qna.csv\", )\n",
    "val_csv['embeddings'] = list(map(lambda x: x.detach().cpu().numpy(), val_embeddings))\n",
    "\n",
    "val_qna_pkl = pd.read_pickle(\"./val_qna_initial.pkl\")[[\"user_id\", \"multiple_responses\", \"question\", \"choices\", \"correct\", \"student_answer\", \"start_time\"]]\n",
    "val_qna_pkl[\"embedding\"] = val_csv.groupby(\"question_index\").apply(lambda x: x.iloc[-1])[\"embeddings\"]\n",
    "val_qna_pkl.to_pickle(\"./val_pkl_with_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv = pd.read_csv(\"./test_qna.csv\", )\n",
    "test_csv['embeddings'] = list(map(lambda x: x.detach().cpu().numpy(), test_embeddings))\n",
    "\n",
    "test_qna_pkl = pd.read_pickle(\"./test_qna_initial.pkl\")[[\"user_id\", \"multiple_responses\", \"question\", \"choices\", \"correct\", \"student_answer\", \"start_time\"]]\n",
    "test_qna_pkl[\"embedding\"] = test_csv.groupby(\"question_index\").apply(lambda x: x.iloc[-1])[\"embeddings\"]\n",
    "test_qna_pkl.to_pickle(\"./test_pkl_with_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>multiple_responses</th>\n",
       "      <th>question</th>\n",
       "      <th>choices</th>\n",
       "      <th>correct</th>\n",
       "      <th>student_answer</th>\n",
       "      <th>start_time</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>387604</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;p&gt;Marlyne Sahakian ist Assistenzprofessorin a...</td>\n",
       "      <td>[&lt;p&gt;…wundert sich darüber, dass SchweizerInnen...</td>\n",
       "      <td>[False, False, True, False]</td>\n",
       "      <td>[False, True, True, False]</td>\n",
       "      <td>2021-10-31 18:36:44.534</td>\n",
       "      <td>[0.24643469, -0.05258508, 0.5322496, -0.043402...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>387604</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;strong&gt;Wähle die korrekte Pluralform(en) als ...</td>\n",
       "      <td>[die Daten, die Data, die Datume]</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>[True, False, False]</td>\n",
       "      <td>2021-11-09 07:57:38.255</td>\n",
       "      <td>[0.22013251, -0.052667905, 0.59776336, -0.0211...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  multiple_responses  \\\n",
       "0   387604                True   \n",
       "1   387604                True   \n",
       "\n",
       "                                            question  \\\n",
       "0  <p>Marlyne Sahakian ist Assistenzprofessorin a...   \n",
       "1  <strong>Wähle die korrekte Pluralform(en) als ...   \n",
       "\n",
       "                                             choices  \\\n",
       "0  [<p>…wundert sich darüber, dass SchweizerInnen...   \n",
       "1                  [die Daten, die Data, die Datume]   \n",
       "\n",
       "                       correct              student_answer  \\\n",
       "0  [False, False, True, False]  [False, True, True, False]   \n",
       "1         [True, False, False]        [True, False, False]   \n",
       "\n",
       "               start_time                                          embedding  \n",
       "0 2021-10-31 18:36:44.534  [0.24643469, -0.05258508, 0.5322496, -0.043402...  \n",
       "1 2021-11-09 07:57:38.255  [0.22013251, -0.052667905, 0.59776336, -0.0211...  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_with_embeddings = pd.concat((train_qna_pkl, val_qna_pkl, test_qna_pkl), ignore_index=True)\n",
    "qna_with_embeddings.to_pickle(\"merged_qna_with_embeddings.pkl\")\n",
    "qna_with_embeddings.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
